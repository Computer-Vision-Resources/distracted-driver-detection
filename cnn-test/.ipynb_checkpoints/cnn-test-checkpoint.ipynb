{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the batch files in the dataset contains a **dictionary** with the following elements:\n",
    "\n",
    "* **data**: a 10,000 x 3072 numpy array of uint8s. Each row of the array stores a 32x32 colour image. The first 1024 entries contain the red channel values, the next 1024 the green, and the final 1024 the blue. The image is stored in row-major order, so that the first 32 entries of the array are the red channel values of the first row of the image.<br><br>\n",
    "\n",
    "* **labels**: a list of 10,000 numbers in the range 0-9. The number at index i indicates the label of the ith image in the array data.\n",
    "\n",
    "Additionally, it includes a `batches.meta` file, which contains:\n",
    "\n",
    "* **label_names**: a 10-element list which gives meaningful names to the numeric labels in the labels array described above. For example, `label_names[0]==\"airplane\"`, `label_names[1]==\"automobile\"`, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaning is imoprtatnt to minimize error, specially when it comes to overfitting. Some strategies are:\n",
    "\n",
    "1. If you have an image in color, convert it to grayscale to lower the dimensionality of the input data, and consequently lower the number of parameters.<br><br>\n",
    "\n",
    "2. Also, consider center-cropping the image, since edges of an image may not provide useful information.<br><br>\n",
    "\n",
    "3. The input should also be normalized by subtracting the mean and dividing by the standard deviation of each data sample so that the gradients during back-propagation don't change too dramatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    \n",
    "    print(\"Before resizing: \" + str(data.shape))\n",
    "    \n",
    "    # the data is now a 32x32 matrix with 3 channels\n",
    "    all_images = data.reshape(data.shape[0], 3, 32, 32)\n",
    "    \n",
    "    print(\"After resizing: \" + str(all_images.shape))\n",
    "    \n",
    "    # grayscale the image by averaging the color intensities\n",
    "    grayscale_images = all_images.mean(1)\n",
    "    \n",
    "    # crop the 32x32 image to a 24x24 image\n",
    "    cropped_images = grayscale_images[:, 4:28, 4:28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    \n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(dir_name):\n",
    "    \n",
    "    meta_dir = (\"{}/batches.meta\".format(directory))\n",
    "    names = unpickle(meta_dir)[b\"label_names\"]\n",
    "\n",
    "    # want to collect all batches into a single data and label matrixes\n",
    "    data, labels = [], []\n",
    "\n",
    "    # 5 = number of batches\n",
    "    for i in range(1, 6): # iterate through them\n",
    "\n",
    "        filename = \"{}/data_batch_{}\".format(directory, i)\n",
    "\n",
    "        # for each data batch, unpickle it. we get a dictionary back.\n",
    "        batch_data = unpickle(filename)\n",
    "\n",
    "        # if theres already content in the data array\n",
    "        if len(data) > 0:\n",
    "            data = np.vstack((data, batch_data[b\"data\"]))\n",
    "            labels = np.hstack((labels, batch_data[b\"labels\"]))\n",
    "        else:\n",
    "            data = batch_data[b\"data\"]\n",
    "            labels = batch_data[b\"labels\"]\n",
    "\n",
    "    return names, data, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before resizing: (50000, 3072)\n",
      "After resizing: (50000, 3, 32, 32)\n",
      "(50000, 576)\n",
      "576\n"
     ]
    }
   ],
   "source": [
    "directory = \"./cfar10\"\n",
    "names, data, labels = read_data(directory)\n",
    "clean_data = clean_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
