{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout,Flatten, Dense\n",
    "from keras import applications\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Tweakable\n",
    "epochs = 1\n",
    "batch_size = 16\n",
    "\n",
    "#Constants\n",
    "target_img_width, target_img_height = 150,150\n",
    "train_dir = '../../../dataset/split_data/train/'\n",
    "val_dir = '../../../dataset/split_data/validation/'\n",
    "train_features_file = \"train_features.npy\"\n",
    "val_features_file = \"val_features.npy\"\n",
    "num_classes = 10\n",
    "top_model_weights_path = 'top_model_weights.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract feature-vectors from VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features(model, data_dir):\n",
    "    #Create a generator to load the data\n",
    "    datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "    generator = datagen.flow_from_directory(data_dir, \n",
    "                                            target_size=(target_img_width, target_img_height),\n",
    "                                            batch_size=batch_size, \n",
    "                                            class_mode=None, #only the data, without labels\n",
    "                                            shuffle=False) #keep data ordered \n",
    "    #Extract information about the data\n",
    "    num_samples = len(generator.filenames)\n",
    "    num_classes = len(generator.class_indices)\n",
    "    \n",
    "    #Obtain number of steps required\n",
    "    steps = ceil(num_samples / batch_size)\n",
    "    #print(\"steps %s\" % steps)\n",
    "    \n",
    "    #Obtain the bottleneck features before the dense layers\n",
    "    features = model.predict_generator(generator, steps=steps, verbose=1)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_vgg16_features():\n",
    "    #Load the VGG16 Model\n",
    "    model = applications.VGG16(include_top=False, weights=\"imagenet\")\n",
    "    \n",
    "    #-----------------TRAINING DATA------------------\n",
    "    #Run the training data through vgg and obtain the corresponding features\n",
    "    train_features = get_features(model, train_dir)                \n",
    "    \n",
    "    #Save the training features in a numpy file\n",
    "    np.save(train_features_file, train_features)\n",
    "    print(\"Saved Training Features in %s\" % train_features_file)\n",
    "    \n",
    "    #-----------------VALIDATION DATA------------------\n",
    "    #Run the training data through vgg and obtain the corresponding features\n",
    "    val_features = get_features(model, val_dir)                \n",
    "    \n",
    "    #Save the validation features in a numpy file\n",
    "    np.save(val_features_file, val_features)\n",
    "    print(\"Saved Validation Features in %s\" % val_features_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top Model to be Retrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_top_model(final_activation,input_shape):\n",
    "    model = Sequential()  \n",
    "    model.add(Flatten(input_shape=input_shape))  \n",
    "    model.add(Dense(256, activation='relu'))  \n",
    "    model.add(Dropout(0.5))  \n",
    "    model.add(Dense(num_classes, activation=final_activation)) # sigmoid to train, softmax for prediction\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data_and_labels(features_file, data_dir):\n",
    "    #Create the datagen\n",
    "    datagen = ImageDataGenerator(rescale=1.0/255.0) \n",
    "        \n",
    "    #Create the generator to load the data\n",
    "    generator = datagen.flow_from_directory(data_dir, \n",
    "                                            target_size=(target_img_width, target_img_height),\n",
    "                                            batch_size=batch_size,\n",
    "                                            class_mode='categorical', #specify categorical\n",
    "                                            shuffle=False #Data is ordered\n",
    "                                           )\n",
    "    #Obtain information about the data\n",
    "    num_samples = len(generator.filenames)\n",
    "    num_classes = len(generator.class_indices)\n",
    "    \n",
    "    #Load the training data features\n",
    "    data = np.load(features_file)\n",
    "    \n",
    "    #Obtain class labels from the generator\n",
    "    labels = generator.classes    \n",
    "    #Convert into onehot \n",
    "    labels_onehot = to_categorical(labels, num_classes=num_classes)\n",
    "    \n",
    "    return data, labels_onehot\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_top_model():\n",
    "    # Load the TRAINING data and labels\n",
    "    train_data, train_labels = load_data_and_labels(train_features_file, train_dir)\n",
    "    \n",
    "    print(train_data.shape, train_labels.shape) #temp\n",
    "    \n",
    "    # Load the VALIDATION data and labels\n",
    "    val_data, val_labels = load_data_and_labels(val_features_file, val_dir)\n",
    "    \n",
    "    print(val_data.shape, val_labels.shape) #temp\n",
    "    \n",
    "    #Create the top model to be trained\n",
    "    model = create_top_model(\"sigmoid\",train_data.shape[1:])\n",
    "    \n",
    "    #Compile the model\n",
    "    model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    #Train the model\n",
    "    model.fit(train_data, \n",
    "              train_labels,\n",
    "              epochs=epochs,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(val_data, val_labels)\n",
    "             )\n",
    "    \n",
    "    #Save the trained weights of the model\n",
    "    model.save_weights(top_model_weights_path)\n",
    "    \n",
    "#     #Obtain a final Accuracy\n",
    "    (loss, accuracy) = model.evaluate(val_data, val_labels, batch_size=batch_size, verbose=1)\n",
    "    \n",
    "#     print(\"------------TOTAL-----------\")\n",
    "    print(\"Final Accuracy =\", accuracy*100, \"%\")\n",
    "    print(\"Final Loss=\", loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_prediction_from_image(img_path):\n",
    "    \n",
    "    class_labels = ['safe_driving', 'texting_right', 'talking_on_phone_right', 'texting_left', 'talking_on_phone_left',\n",
    "                'operating_radio', 'drinking', 'reaching_behind', 'doing_hair_makeup', 'talking_to_passanger']\n",
    "\n",
    "    target_size=(150,150)\n",
    "\n",
    "    # prepare image for classification using keras utility functions\n",
    "    image = load_img(img_path, target_size=target_size)\n",
    "    \n",
    "    # print image\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    image = img_to_array(image) # convert from PIL Image to NumPy array\n",
    "    image /= 255\n",
    "    # the dimensions of image should now be (150, 150, 3)\n",
    "\n",
    "    # to be able to pass it through the network and use batches, we want it with shape (1, 224, 224, 3)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    # print(image.shape)\n",
    "\n",
    "    # build the VGG16 network  \n",
    "    model = applications.VGG16(include_top=False, weights='imagenet')  \n",
    "\n",
    "    # get the bottleneck prediction from the pre-trained VGG16 model  \n",
    "    bottleneck_prediction = model.predict(image) \n",
    "    \n",
    "    # build top model  \n",
    "    model = create_top_model(\"softmax\",bottleneck_prediction.shape[1:])\n",
    "\n",
    "    model.load_weights(top_model_weights_path)  \n",
    "\n",
    "    # use the bottleneck prediction on the top model to get the final classification  \n",
    "    class_predicted = model.predict_classes(bottleneck_prediction) \n",
    "    \n",
    "    probs = model.predict(bottleneck_prediction) \n",
    "    decoded_predictions = dict(zip(class_labels, probs[0]))\n",
    "    decoded_predictions = sorted(decoded_predictions.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    \n",
    "    count = 1\n",
    "    for key, value in decoded_predictions[:5]:\n",
    "        print(\"{}. {}: {:8f}%\".format(count, key, value*100))\n",
    "        count+=1\n",
    "\n",
    "    # print(class_predicted)\n",
    "    # print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13447 images belonging to 10 classes.\n",
      "(13447, 4, 4, 512) (13447, 10)\n",
      "Found 4487 images belonging to 10 classes.\n",
      "(4487, 4, 4, 512) (4487, 10)\n",
      "Train on 13447 samples, validate on 4487 samples\n",
      "Epoch 1/1\n",
      "  816/13447 [>.............................] - ETA: 43s - loss: 2.5024 - acc: 0.1287"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #extract_vgg16_features() #Takes quite a bit of time on CPU\n",
    "    train_top_model()\n",
    "    get_prediction_from_image(\"../../../dataset/split_data/test/c0/img_42043.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
