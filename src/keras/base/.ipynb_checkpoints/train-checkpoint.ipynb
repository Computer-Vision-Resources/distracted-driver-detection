{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convnet trained from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data pre-processing and data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\" Data augmentation is one way to fight overfitting, but it isn't enough since our augmented samples are still highly correlated. Your main focus for fighting overfitting should be the **entropic capacity** of your model --how much information your model is allowed to store. A model that can store a lot of information has the potential to be more accurate by leveraging more features, but it is also more at risk to start storing irrelevant features. Meanwhile, a model that can only store a few features will have to focus on the most significant features found in the data, and these are more likely to be truly relevant and to generalize better.\n",
    "\n",
    "There are different ways to modulate entropic capacity. The main one is the choice of the number of parameters in your model, i.e. the number of layers and the size of each layer. Another way is the use of weight regularization, such as $L_1$ or $L_2$ regularization, which consists in forcing model weights to taker smaller values.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Dropout also helps reduce overfitting, by preventing a layer from seeing twice the exact same pattern, thus acting in a way analoguous to data augmentation (you could say that both dropout and data augmentation tend to disrupt random correlations occuring in your data).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from model import create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# using flow_from_directory(), generate batches of image data (and their labels)\n",
    "batch_size = 40\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "            rotation_range=10, # range (0-180) within which to randomly rotate pictures\n",
    "            # width_shift_range=0.2, # as fraction of width, range within to which randomly translate pictures\n",
    "            # height_shift_range=0.2, # same as above, but with height\n",
    "            rescale=1./255, # RBG coefficient values 0-255 are too hight to process. instead, represent them as values 0-1\n",
    "            # shear_range=0.2, # random shearing transformations\n",
    "            zoom_range=0.1, # randomly zooming inside pictures\n",
    "            horizontal_flip=False,\n",
    "            fill_mode='nearest') # strategy for filling in newly created pixels, which can appear after a rotation or a width/height shift\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "            rotation_range=10, # range (0-180) within which to randomly rotate pictures\n",
    "            # width_shift_range=0.2, # as fraction of width, range within to which randomly translate pictures\n",
    "            # height_shift_range=0.2, # same as above, but with height\n",
    "            rescale=1./255, # RBG coefficient values 0-255 are too hight to process. instead, represent them as values 0-1\n",
    "            # shear_range=0.2, # random shearing transformations\n",
    "            zoom_range=0.1, # randomly zooming inside pictures\n",
    "            horizontal_flip=False,\n",
    "            fill_mode='nearest') # strategy for filling in newly created pixels, which can appear after a rotation or a width/height shift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate batches of augmented image data, given the path of the original images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate generators of augmented image batches (and their labels) via .flow(data, labels) or .flow_from_directory(directory)\n",
    "# this generator will read pictures found in subfolders and indefinitely generate batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        '../dataset/split_data/train',  # this is the target directory\n",
    "        target_size=(150, 150),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "        '../dataset/split_data/validation',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the generators above to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath=\"weights.h5\"\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "                        filepath,\n",
    "                        monitor='val_acc',\n",
    "                        verbose=1,\n",
    "                        save_best_only=True,\n",
    "                        mode='max')\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "                monitor='val_acc',\n",
    "                # verbose=0, # decides what to print\n",
    "                # min_delta=0, # threshold to whether quantify a loss at some epoch as improvement or not. If the difference of loss is below min_delta, it is quantified as no improvement\n",
    "                # mode='auto', # depends on the direction of the monitored quantity (is it supposed to be decreasing or increasing), since we monitor the loss, we can use min.        \n",
    "                patience=3,\n",
    "                mode='max') \n",
    "\n",
    "callbacks_list = [checkpoint_callback, early_stop_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=len(train_generator.filenames) // batch_size,\n",
    "            epochs=50,\n",
    "            validation_data=val_generator,\n",
    "            validation_steps=len(val_generator.class_indices) // batch_size,\n",
    "            callbacks=callbacks_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
