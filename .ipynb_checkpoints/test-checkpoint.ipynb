{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the batch files in the dataset contains a **dictionary** with the following elements:\n",
    "\n",
    "* **data**: a 10,000 x 3072 numpy array of uint8s. Each row of the array stores a 32x32 colour image. The first 1024 entries contain the red channel values, the next 1024 the green, and the final 1024 the blue. The image is stored in row-major order, so that the first 32 entries of the array are the red channel values of the first row of the image.<br><br>\n",
    "\n",
    "* **labels**: a list of 10,000 numbers in the range 0-9. The number at index i indicates the label of the ith image in the array data.\n",
    "\n",
    "Additionally, it includes a `batches.meta` file, which contains:\n",
    "\n",
    "* **label_names**: a 10-element list which gives meaningful names to the numeric labels in the labels array described above. For example, `label_names[0]==\"airplane\"`, `label_names[1]==\"automobile\"`, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaning is imoprtatnt to minimize error, specially when it comes to overfitting. Some strategies are:\n",
    "\n",
    "1. If you have an image in color, convert it to grayscale to lower the dimensionality of the input data, and consequently lower the number of parameters.<br><br>\n",
    "\n",
    "2. Also, consider center-cropping the image, since edges of an image may not provide useful information.<br><br>\n",
    "\n",
    "3. The input should also be normalized by subtracting the mean and dividing by the standard deviation of each data sample so that the gradients during back-propagation don't change too dramatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    \n",
    "    print(\"Original data: \" + str(data.shape))\n",
    "    \n",
    "    # the data is now a 32x32 matrix with 3 channels\n",
    "    all_images = data.reshape(data.shape[0], 3, 32, 32)\n",
    "    print(\"> After resizing: \" + str(all_images.shape)) # (50000, 3, 32, 32)\n",
    "    \n",
    "    # grayscale the image by averaging the color intensities\n",
    "    grayscale_images = all_images.mean(1)\n",
    "    print(\"> After greyscale: \" + str(grayscale_images.shape)) # (50000, 32, 32)\n",
    "    \n",
    "    # crop the 32x32 image to a 24x24 image\n",
    "    cropped_images = grayscale_images[:, 4:28, 4:28] # exclude 4 units at the top, bottom, left and right\n",
    "    print(\"> After cropping: \" + str(cropped_images.shape)) # (50000, 24, 24)\n",
    "    \n",
    "    # flattening the 50,000 images into an array\n",
    "    image_data = cropped_images.reshape(data.shape[0], -1)\n",
    "    print(\"> After reshape: \" + str(image_data.shape)) # (50000, 576)\n",
    "    \n",
    "    image_size = image_data.shape[1] # 576\n",
    "    \n",
    "    # get mean of each row and make it (5000, 1) - not (5000,)\n",
    "    means = np.mean(image_data, axis=1).reshape(len(data), 1)\n",
    "    \n",
    "    # get std of each row and make it (5000, 1) - not (5000,)\n",
    "    stds = np.std(image_data, axis=1).reshape(len(data), 1)\n",
    "    adj_stds = np.maximum(stds, 1.0/np.sqrt(image_size))\n",
    "    \n",
    "    # normalize the pixel values by subtracting the mean and diving by the std\n",
    "    normalized_images = (image_data - means) / adj_stds\n",
    "    print(\"> After normalized: \" + str(normalized_images.shape))\n",
    "    \n",
    "    return normalized_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    \n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(dir_name):\n",
    "    \n",
    "    meta_dir = (\"{}/batches.meta\".format(directory))\n",
    "    names = unpickle(meta_dir)[b\"label_names\"]\n",
    "\n",
    "    # want to collect all batches into a single data and label matrixes\n",
    "    data, labels = [], []\n",
    "\n",
    "    # 5 = number of batches\n",
    "    for i in range(1, 6): # iterate through them\n",
    "\n",
    "        filename = \"{}/data_batch_{}\".format(directory, i)\n",
    "\n",
    "        # for each data batch, unpickle it. we get a dictionary back.\n",
    "        batch_data = unpickle(filename)\n",
    "\n",
    "        # if theres already content in the data array\n",
    "        if len(data) > 0:\n",
    "            data = np.vstack((data, batch_data[b\"data\"]))\n",
    "            labels = np.hstack((labels, batch_data[b\"labels\"]))\n",
    "        else:\n",
    "            data = batch_data[b\"data\"]\n",
    "            labels = batch_data[b\"labels\"]\n",
    "\n",
    "    data = clean_data(data).astype(np.float32)\n",
    "            \n",
    "    return names, data, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_some_examples(names, data, labels):\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    rows, cols = 4, 4 # these are arbitrary\n",
    "    random_ids = random.sample(range(len(data)), rows*cols) # randomly select the images\n",
    "    \n",
    "    for i in range(rows*cols):\n",
    "        \n",
    "        plt.subplot(rows, cols, i+1)\n",
    "        curr_index = random_ids[i]\n",
    "        plt.title(names[labels[curr_index]])\n",
    "        \n",
    "        image = np.reshape(data[curr_index, :], (24, 24))\n",
    "        # plt.imshow(image, cmap='Greys_r')\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# randomly initialize 32 filters. these will be the features/weights\n",
    "def show_weights(W, filename=None):\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    \n",
    "    # define just enough rows and columns to show 32 figures\n",
    "    rows, cols = 4, 8\n",
    "    \n",
    "    # visualize each filter matrix\n",
    "    for i in range(np.shape(W)[3]): # 0 to 31\n",
    "\n",
    "        image = W[:, :, 0, i]\n",
    "        plt.subplot(rows, cols, i+1)\n",
    "        plt.imshow(image, cmap='Greys_r', interpolation='none')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolve Using Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_conv_results(data, filename=None):\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    rows, cols = 4, 8\n",
    "    \n",
    "    for i in range(np.shape(data)[3]):\n",
    "        image = data[0, :, :, i] # [1, 24, 24, 32]\n",
    "        plt.subplot(rows, cols, i+1)\n",
    "        plt.imshow(image, cmap='Greys_r', interpolation='none')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max-pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"./cfar10\"\n",
    "\n",
    "# read and clean the data\n",
    "names, data, labels = read_data(directory) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_some_examples(names, data, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will convolve an image with a couple of random 5x5: a filter.\n",
    "\n",
    "Filters are a way to extract useful image features such as edges and shapes. With these features, we can train a machine learning model on them. The more filters we use on an image, the greater the dimension of the feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # define the tensor representing the random filters\n",
    "# W = tf.Variable(tf.random_normal([5, 5, 1, 32]))\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "    \n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "#     W_val = sess.run(W)\n",
    "#     show_weights(W_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolve Using Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing convolution\n",
    "\n",
    "raw_data = data[4, :] # get an image from the dataset\n",
    "raw_image = np.reshape(raw_data, (24, 24)) \n",
    "plt.figure()\n",
    "plt.imshow(raw_image, cmap='Greys_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Tensorflow's convolve function on the randomly generated filters.\n",
    "\n",
    "By adding a bias term and an activation function (such as relu), the convolution layer of the network behaves nonlinearly, which improves its expressiveness. After adding a bias term and an activation function, the resulting convolutions can capture more powerful patterns within images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_layer(x, W, bias):\n",
    "    \n",
    "    # given an image x, apply all the filters W to it\n",
    "    conv = tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME') # strides=[batch, height, width, channels]\n",
    "    # note: the padding determines what to do when the window runs out of pixels at the end\n",
    "    conv_with_bias = tf.nn.bias_add(conv, bias)\n",
    "    conv_out = tf.nn.relu(conv_with_bias)\n",
    "\n",
    "    return conv_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # define the input tensor for the 24x24 image\n",
    "# x = tf.reshape(raw_data, shape=[-1, 24, 24, 1])\n",
    "\n",
    "# # define the filters and corresponding parameters\n",
    "# bias = tf.Variable(tf.random_normal([32])) # of length/shape = 32\n",
    "\n",
    "# # given an image x, apply all the filters W to it\n",
    "# conv = tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME') # strides=[batch, height, width, channels]\n",
    "# conv_with_bias = tf.nn.bias_add(conv, bias)\n",
    "# conv_out = tf.nn.relu(conv_with_bias)\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "    \n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "#     conv_val = sess.run(conv)\n",
    "#     print((conv_val).shape)\n",
    "#     show_conv_results(conv_val)\n",
    "    \n",
    "#     conv_out_val = sess.run(conv_out)\n",
    "#     print((conv_val).shape)\n",
    "#     show_conv_results(conv_out_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max-pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is done to reduce the size of the convolved outputs. By rescaling/subsampling the output, we can reduce the number of parameters - which helps avoid overfitting the data.\n",
    "\n",
    "In max-pooling, a window is passed across an image. At each location it stops, it picks the pixel with the maximum value. Depending on the length of the stride, the resulting image is a fraction of the size of the original - but keeps its most relevant features.\n",
    "\n",
    "This lessens the dimentionality of the data, this lowering the number of parameters in future steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_pool_layer(conv, k=2):\n",
    "    \n",
    "    # k: # window size\n",
    "    # strides: steps taken to move across the image\n",
    "    return (tf.nn.max_pool(conv, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# kernel_size = 2 \n",
    "# max_pool = max_pool_layer(conv_out, kernel_size)\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "#     max_pool_val = sess.run(max_pool)\n",
    "#     print(max_pool_val.shape) # the images are now (12,12) - their size was halved\n",
    "#     show_conv_results(max_pool_val) # shown: lower-resolution convolved outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the input and output placeholders\n",
    "x = tf.placeholder(tf.float32, [None, 24 * 24])\n",
    "y = tf.placeholder(tf.float32, [None, len(names)]) # len(names) = number of classes\n",
    "\n",
    "# apply 64 convolutions of window-size 5x5\n",
    "W1 = tf.Variable(tf.random_normal([5, 5, 1, 64])) # want 64 filters (1 -> greyscale)\n",
    "b1 = tf.Variable(tf.random_normal([64]))\n",
    "# at this point, we have 64 images\n",
    "\n",
    "# apply 64 more convolutions of window-size 5x5\n",
    "W2 = tf.Variable(tf.random_normal([5, 5, 64, 64]))\n",
    "b2 = tf.Variable(tf.random_normal([64]))\n",
    "\n",
    "# introduce a fully-connected layer - need to flatten the feature map to shape [batch_size, features]\n",
    "# at this point, we will have maxpooled twice. image size: 24x24 -> 12x12 -> 6x6\n",
    "# 64 is the number of channels.\n",
    "W3 = tf.Variable(tf.random_normal([6*6*64, 1024]))\n",
    "b3 = tf.Variable(tf.random_normal([1024])) # 1024 is the number of perceptrons in this layer\n",
    "\n",
    "# define the variables for a fully-connected layer\n",
    "W_out = tf.Variable(tf.random_normal([1024, len(names)]))\n",
    "b_out = tf.Variable(tf.random_normal([len(names)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model():\n",
    "    \n",
    "    x_reshaped = tf.reshape(x, shape=[-1, 24, 24, 1])\n",
    "    \n",
    "    # construct the first layer of convolution and maxpooling\n",
    "    conv_out1 = conv_layer(x_reshaped, W1, b1)\n",
    "    maxpool_out1 = max_pool_layer(conv_out1)\n",
    "    \n",
    "    # normalizing to \"prevent neurons from saturating when inputs may have varying scale, and to aid generalization.\"\n",
    "    norm1 = tf.nn.local_response_normalization(maxpool_out1, 4, bias=1.0, alpha=0.001/9.0, beta=0.75)\n",
    "\n",
    "    # construct the second layer\n",
    "    conv_out2 = conv_layer(norm1, W2, b2)\n",
    "    norm2 = tf.nn.local_response_normalization(conv_out2, 4, bias=1.0, alpha=0.001/9.0, beta=0.75)\n",
    "    maxpool_out2 = max_pool_layer(norm2)\n",
    "\n",
    "    # construct the fully connected layers\n",
    "    # first, flatten the images. instead of (6,6,64), now 6*6*64 = 2304\n",
    "    maxpool_reshaped = tf.reshape(maxpool_out2, [-1, W3.get_shape().as_list()[0]])\n",
    "    local = tf.add(tf.matmul(maxpool_reshaped, W3), b3)\n",
    "    local_out = tf.nn.relu(local)\n",
    "\n",
    "    out = tf.add(tf.matmul(local_out, W_out), b_out)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_op = model()\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=model_op, labels=y))\n",
    "train_optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(model_op, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "total_batches = 200\n",
    "epochs = 1\n",
    "\n",
    "# loop through the dataset of images in small batches\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    onehot_labels = tf.one_hot(labels, len(names), on_value=1., off_value=0., axis=-1)\n",
    "    onehot_vals = sess.run(onehot_labels)\n",
    "    \n",
    "    batch_size = len(data)//total_batches\n",
    "    print('batch_size: ', batch_size)\n",
    "    \n",
    "    for j in range(0, epochs):\n",
    "        \n",
    "        print('EPOCH ', j+1)\n",
    "        \n",
    "        # train the network in batches\n",
    "        for i in range(0, len(data), batch_size):\n",
    "            \n",
    "            batch_data = data[i: i+batch_size, :]\n",
    "            batch_onehot_vals = onehot_vals[i: i+batch_size, :]\n",
    "            \n",
    "            _, accuracy_val = sess.run([train_optimizer, accuracy], feed_dict={x:batch_data, y:batch_onehot_vals})\n",
    "            \n",
    "            if i % 1000 == 0:\n",
    "                print(i, accuracy_val)\n",
    "                \n",
    "        print('DONE WITH EPOCH')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization Tips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Augment data**: From a single image, you can easily generate new training images. As a start, just flip an image horizontally or vertically and you can quadruple your dataset size. You may also adjust the brightness of the image or the hue to ensure the neural network generalizes to other fluctuations. Lastly, you may even want to add random noise to the image to make the classifier robot to small occlusions.<br><br>\n",
    "\n",
    "* **Early stopping**: Keep track of the training and testing error while you train the neural network. At first, both errors should slowly dwindle down, because the network is learning. But sometimes, the test error goes back up. This is a signal that the neural network has started overfitting on the training data, and is unable to generalize to previously unseen input. You should stop the training the moment you witness this phenomenon.<br><br>\n",
    "\n",
    "* **Regularize weights**: Another way to combat overfitting is by adding a regularization term to the cost function. We’ve already seen regularization in previous chapters, and the same concepts apply here.<br><br>\n",
    "\n",
    "* **Dropout**: TensorFlow comes with a handy function tf.nn.dropout, which can be applied to any layer of the network to reduce overfitting. It turns off a randomly selected number of neurons in that layer during training so that the network must be redundant and robust to inferring output.<br><br>\n",
    "\n",
    "* **Deeper**: A deeper architecture means adding more hidden layers to the neural network. If you have enough training data, it’s been shown that adding more hidden layers improves performance.<br><br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
