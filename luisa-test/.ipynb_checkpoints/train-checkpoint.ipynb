{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the bottleneck features of a pre-trained network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"A pretrained network would have already learned features that are useful for most computer vision problems, and leveraging such features would allow us to reach a better accuracy than any method that would only rely on the available data.\"\n",
    "\n",
    "We will use the VGG16 architecture.\n",
    "\n",
    "\"We will only instantiate the convolutional part of the model, everything up to the fully-connected layers. We will then run this model on our training and validation data once, recording the output (the \"bottleneck features\").\"\n",
    "\n",
    "\"The reason why we are storing the features offline rather than adding our fully-connected model directly on top of a frozen convolutional base and running the whole thing, is computational effiency. Running VGG16 is expensive, especially if you're working on CPU, and we want to only do it once. Note that this prevents us from using data augmentation.\"\n",
    "\n",
    "In short, we will:\n",
    "1. Save the bottleneck features from the VGG16 model.\n",
    "2. Train a small network using the saved features to classify our classes, and save that model (the \"top model\")\n",
    "3. Use both the VGG16 model and the top model to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import applications\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import matplotlib.pyplot as plt  \n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_size=(224, 224)\n",
    "path_top_model_weights = \"bottleneck_fc_model.h5\"\n",
    "epochs = 5 # number of epochs to train the top model\n",
    "batch_size = 16 # to be used by flow_from_directory and predict_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the bottleneck features from the VGG16 model\n",
    "def save_bottleneck_features():\n",
    "    \n",
    "    # create the VGG16 model without the final fully-connected layers and load the ImageNet weights\n",
    "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "    \n",
    "    # create the data generator for training images\n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    train_generator = datagen.flow_from_directory(\n",
    "                        '../dataset/split_data/train/',\n",
    "                        target_size=target_size,\n",
    "                        batch_size=batch_size,\n",
    "                        class_mode=None, # generator will only yield batches of data, no labels\n",
    "                        shuffle=False) # the data will be in order\n",
    "    \n",
    "    # run the training images on the VGG16 model to save the bottleneck features\n",
    "    num_train_samples = len(train_generator.filenames)\n",
    "    num_classes = len(train_generator.class_indices)\n",
    "    \n",
    "    size_train_prediction = int(math.ceil(num_train_samples/batch_size)) # calculate the number of iterations when working\n",
    "                                                                      # on batches when the number of training samples\n",
    "                                                                      # isn't divisible by the batch size\n",
    "            \n",
    "    bottleneck_features_train = model.predict_generator(train_generator, size_train_prediction)\n",
    "    np.save('bottleneck_features_train.npy', bottleneck_features_train)\n",
    "    \n",
    "    # now, do the same with the validation images\n",
    "    val_generator = datagen.flow_from_directory(\n",
    "                        '../dataset/split_data/validation/',\n",
    "                        target_size=target_size,\n",
    "                        batch_size=batch_size,\n",
    "                        class_mode=None, # generator will only yield batches of data, no labels\n",
    "                        shuffle=False) # the data will be in order\n",
    "    \n",
    "    num_val_samples = len(val_generator.filenames)\n",
    "    \n",
    "    size_val_prediction = int(math.ceil(num_val_samples/batch_size)) # calculate the number of iterations when working\n",
    "                                                                      # on batches when the number of training samples\n",
    "                                                                      # isn't divisible by the batch size\n",
    "            \n",
    "    bottleneck_features_val = model.predict_generator(val_generator, size_val_prediction)\n",
    "    \n",
    "    np.save('bottleneck_features_val.npy', bottleneck_features_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train the top model\n",
    "def train_top_model():\n",
    "    \n",
    "    # ---------- PREPARE DATA FOR TRAINING ----------\n",
    "    \n",
    "    top_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    # to train the top model, we need class labels for each of the samples in training and validation\n",
    "    top_model_train_generator = top_datagen.flow_from_directory(\n",
    "                            '../dataset/split_data/train/',\n",
    "                            target_size=target_size,\n",
    "                            batch_size=batch_size,\n",
    "                            class_mode='categorical',\n",
    "                            shuffle=False)\n",
    "    \n",
    "    num_train_samples = len(top_model_train_generator.filenames)\n",
    "    num_classes = len(top_model_train_generator.class_indices)\n",
    "    \n",
    "    # load the previously saved bottleneck features\n",
    "    vgg_train_data = np.load('bottleneck_features_train.npy')\n",
    "    \n",
    "    # get class labels and convert them to categorical vectors\n",
    "    train_labels = to_categorical(top_model_train_generator.classes, num_classes=num_classes)\n",
    "    \n",
    "    # repeat the process with validation images\n",
    "    top_model_val_generator = top_datagen.flow_from_directory(\n",
    "                            '../dataset/split_data/validation/',\n",
    "                            target_size=target_size,\n",
    "                            batch_size=batch_size,\n",
    "                            class_mode='categorical',\n",
    "                            shuffle=False)\n",
    "    \n",
    "    num_val_samples = len(top_model_val_generator.filenames)\n",
    "    \n",
    "    # load the previously saved bottleneck features\n",
    "    vgg_val_data = np.load('bottleneck_features_val.npy')\n",
    "    \n",
    "    # get class labels and convert them to categorical vectors\n",
    "    val_labels = to_categorical(top_model_val_generator.classes, num_classes=num_classes)\n",
    "    \n",
    "    # ---------- CREATE AND TRAIN THE TOP MODEL ----------\n",
    "    # use the bottleneck features as input\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=vgg_train_data.shape[1:]))  \n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(\n",
    "                vgg_train_data,\n",
    "                train_labels,\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                validation_data=(vgg_val_data, val_labels))\n",
    "    \n",
    "    model.save_weights(path_top_model_weights)\n",
    "    \n",
    "    # ---------- TEST MODEL ----------\n",
    "    \n",
    "    loss, acc = model.evaluate(  \n",
    "                        vgg_val_data,\n",
    "                        val_labels,\n",
    "                        batch_size=batch_size,\n",
    "                        verbose=1)\n",
    "\n",
    "    print(\"loss: {}\".format(loss))\n",
    "    print(\"accuracy: {:.5f}%\".format(acc * 100))\n",
    "    \n",
    "    plt.figure(1)  \n",
    "    \n",
    "    # ---------- PLOT TRAINING AND TESTING RESULTS ----------\n",
    "   \n",
    "    # summarize history for accuracy\n",
    "    plt.subplot(211)\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "    # summarize history for loss\n",
    "    plt.subplot(212)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "('Invalid class_mode:', False, '; expected one of \"categorical\", \"binary\", \"sparse\", \"input\" or None.')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-d7e2cd7206cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msave_bottleneck_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_top_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-6d44cb123ca1>\u001b[0m in \u001b[0;36msave_bottleneck_features\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m                         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                         \u001b[0mclass_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# generator will only yield batches of data, no labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                         shuffle=False) # the data will be in order\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# run the training images on the VGG16 model to save the bottleneck features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/luisarojas/anaconda/lib/python3.6/site-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, interpolation)\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mfollow_links\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_links\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m             interpolation=interpolation)\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/luisarojas/anaconda/lib/python3.6/site-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, interpolation)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                               'input', None}:\n\u001b[1;32m   1045\u001b[0m             raise ValueError('Invalid class_mode:', class_mode,\n\u001b[0;32m-> 1046\u001b[0;31m                              \u001b[0;34m'; expected one of \"categorical\", '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                              \u001b[0;34m'\"binary\", \"sparse\", \"input\"'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m                              ' or None.')\n",
      "\u001b[0;31mValueError\u001b[0m: ('Invalid class_mode:', False, '; expected one of \"categorical\", \"binary\", \"sparse\", \"input\" or None.')"
     ]
    }
   ],
   "source": [
    "save_bottleneck_features()\n",
    "train_top_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
