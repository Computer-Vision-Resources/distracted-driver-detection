{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications import imagenet_utils\n",
    "from keras import applications\n",
    "import numpy as np\n",
    "import operator\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes=10\n",
    "path_top_model_weights = \"bottleneck_fc_model.h5\"\n",
    "target_size=(224, 224)\n",
    "img_path = \"../dataset/split_data/test/c0/img_41813.jpg\"\n",
    "class_labels = ['safe_driving', 'texting_right', 'talking_on_phone_right', 'texting_left', 'talking_on_phone_left',\n",
    "                'operating_radio', 'drinking', 'reaching_behind', 'doing_hair_makeup', 'talking_to_passanger']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare image for classification using keras utility functions\n",
    "image = load_img(img_path, target_size=target_size)\n",
    "\n",
    "image_arr = img_to_array(image) # convert from PIL Image to NumPy array\n",
    "# the dimensions of image should now be (224, 224, 3)\n",
    "\n",
    "image_arr /= 255 # re-scale from [0-225] to [0-1]\n",
    "\n",
    "# to be able to pass it through the network and use batches, we want it with shape (1, 224, 224, 3)\n",
    "image_arr = np.expand_dims(image_arr, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the VGG16 network\n",
    "model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "\n",
    "# get the bottleneck prediction from the pre-trained vgg16 model\n",
    "bottleneck_prediction = model.predict(image_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the top model\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=bottleneck_prediction.shape[1:])) # use bottleneck prediction as input\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# get weights from trained top model\n",
    "model.load_weights(path_top_model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the bottleneck prediction on the top model to get the final classification\n",
    "class_predicted = model.predict_classes(bottleneck_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# classify given an image\n",
    "predictions = model.predict(image_arr)\n",
    "\n",
    "# get human-readable labels of the preditions, as well as the corresponding probability\n",
    "decoded_predictions = dict(zip(class_labels, predictions[0]))\n",
    "\n",
    "# sort dictionary by value\n",
    "decoded_predictions = sorted(decoded_predictions.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "# print image\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "count = 1\n",
    "for key, value in decoded_predictions[:5]:\n",
    "    print(\"{}. {}: {:8f}%\".format(count, key, value*100))\n",
    "    count+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
